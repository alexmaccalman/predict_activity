---
title: "predict_activity"
author: "Alex MacCalman"
date: "9/8/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#set up parallel processing
doParallel::registerDoParallel()
library(knitr)
library(tidyverse)
library(dplyr)
library(tidymodels)
library(GGally)
library(skimr)
library(corrr)
library(naniar)
library(glmnet)
library(tidypredict)
library(yaml)
```
This project develops a prediction model to predict whether a person lifts a barbell correctly or incorrectly in 5 different ways. More information is available from the website [here:](http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset)).


# Load and explore the data.  
```{r}
data_raw <- read_csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
valid_raw <- read_csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
#explore data variables
skim((data_raw))
#explore the missing value impacts
#select missing data
missing_data <- data_raw %>%
  select_if(~ any(is.na(.)))

missing_data %>% 
  gg_miss_upset()

# eliminate the variables with the missing data in training data
data_clean <- data_raw %>%
  select_if(~ !any(is.na(.))) %>% 
  select(-cvtd_timestamp, -new_window, -X1, -raw_timestamp_part_1, -raw_timestamp_part_2, -num_window)

data_clean$classe <- as.factor(data_clean$classe)

# eliminate the variables with the missing data in testing data
valid_clean <- valid_raw %>%
  select_if(~ !any(is.na(.))) %>% 
  select(-user_name, -cvtd_timestamp, -new_window, -X1, -raw_timestamp_part_1, -raw_timestamp_part_2, -num_window, -problem_id)


# narrow in on the reduced data set
skim(data_clean)
#train <- as_tibble(train)
#glimpse(train)

data_clean %>% 
  count(classe) %>% 
  mutate(prop = n/sum(n))

##Explore the numeric correlations. 
all_numeric <- select_if(data_clean, is.numeric)

cor_threshold <- 0.8
correlate(all_numeric) %>% 
  stretch() %>% 
  mutate(threshold = case_when(r > cor_threshold | r < -cor_threshold ~ 1,
                          TRUE ~ 0)) %>%
  count(threshold)

cor <- correlate(all_numeric) %>% 
  stretch() %>% 
  filter(r > cor_threshold | r < -cor_threshold, r != 1) %>% 
  arrange(desc(r))

high_cor <- all_numeric %>% 
  select(as.character(cor$x))

high_cor %>% 
  correlate() %>% 
  rearrange(method = "MDS", absolute = FALSE) %>% 
  shave() %>% 
  rplot(shape = 19, colors = c("red", "green"))

# explore k-means clusters 
# select variables we want to cluster on
points <- data_clean %>% 
  select(-classe, -user_name)

#explore the number of clusters
kclusts <- 
  tibble(k = 1:20) %>%
  mutate(
    kclust = map(k, ~kmeans(points, .x)),
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, points)
  )
# assign separate lists
clusters <- 
  kclusts %>%
  unnest(cols = c(tidied))

assignments <- 
  kclusts %>% 
  unnest(cols = c(augmented))

clusterings <- 
  kclusts %>%
  unnest(cols = c(glanced))

#find best number of clusters
ggplot(clusterings, aes(k, tot.withinss)) +
  geom_line() +
  geom_point()
```
# Split the training and testing sets and set up cross validation
```{r}
set.seed(123)
data_split <- initial_split(data_clean, strata = classe)
train <- training(data_split)
test <- testing(data_split)
# create the cross validation sets
vfolds <- vfold_cv(train, v = 3, strata = classe) # 3 folds

```


# Fit a xgboost model
```{r}
# Build xgboost specification
xgb_spec <- boost_tree() %>% 
        set_engine("xgboost") %>% 
        set_mode("classification")
# Build the xgboost workflow
# we don't need a recipe. We will use all the data
xgb_wf <- workflow() %>% 
        add_formula(classe ~ .) %>% 
        add_model(xgb_spec)
```
 
## Fit the xgboost model
```{r, cache = TRUE}
set.seed(234)

#fit on 3 folds
xgb_result <- fit_resamples(
  xgb_wf,
  resamples = vfolds,
  control = control_resamples(save_pred = TRUE)
)
# explore the results
xgb_result %>% 
  collect_metrics()
# create a confusion matrix
xgb_result %>% 
  collect_predictions() %>% 
  conf_mat(classe, .pred_class)

final_model <- xgb_wf %>% 
        fit(data = (train %>% select(-user_name))) %>% 
        pull_workflow_fit()
```

# Test Predictions  
```{r}
predictions <- 
  predict(final_model, new_data = valid_clean)
```

